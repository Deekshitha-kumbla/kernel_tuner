{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Matrix multiplication\n",
    "\n",
    "Matrix multiplication is one of the most well-known linear algebra algorithms, and frequently used to demonstrate the high-performance computing capabilities of GPUs. As such, an example using matrix multiplication could not be left out. A naive CUDA kernel for a square matrix multiplication is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load matmul_naive.cu\n",
    "#define WIDTH 4096\n",
    "\n",
    "__global__ void matmul_kernel(float *C, float *A, float *B) {\n",
    "    int x = blockIdx.x * block_size_x + threadIdx.x;\n",
    "    int y = blockIdx.y * block_size_y + threadIdx.y;\n",
    "    float sum = 0.0;\n",
    "\n",
    "    for (int k=0; k<WIDTH; k++) {\n",
    "        sum += A[y*WIDTH+k] * B[k*WIDTH+x];\n",
    "    }\n",
    "\n",
    "    C[y*WIDTH+x] = sum;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel simply creates a single thread per output element. Each thread computes the index of the element it is responsible for, and iterates over the corresponding row in A, and corresponding column in B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: GeForce GTX TITAN X\n",
      "block_size_x=16, block_size_y=1, time=1649.89187012\n",
      "block_size_x=16, block_size_y=2, time=832.841296387\n",
      "block_size_x=16, block_size_y=4, time=793.8703125\n",
      "block_size_x=16, block_size_y=8, time=728.78170166\n",
      "block_size_x=16, block_size_y=16, time=574.705957031\n",
      "block_size_x=16, block_size_y=32, time=494.258599854\n",
      "block_size_x=32, block_size_y=1, time=977.559960938\n",
      "block_size_x=32, block_size_y=2, time=867.61730957\n",
      "block_size_x=32, block_size_y=4, time=830.580737305\n",
      "block_size_x=32, block_size_y=8, time=623.53215332\n",
      "block_size_x=32, block_size_y=16, time=548.464074707\n",
      "block_size_x=32, block_size_y=32, time=514.333398438\n",
      "block_size_x=64, block_size_y=1, time=963.868127441\n",
      "block_size_x=64, block_size_y=2, time=952.567932129\n",
      "block_size_x=64, block_size_y=4, time=789.973242187\n",
      "block_size_x=64, block_size_y=8, time=678.554589844\n",
      "block_size_x=64, block_size_y=16, time=602.40604248\n",
      "best performing configuration: block_size_x=16, block_size_y=32, time=494.258599854\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy\n",
    "import kernel_tuner\n",
    "from collections import OrderedDict\n",
    "\n",
    "problem_size = (4096, 4096)\n",
    "size = numpy.prod(problem_size)\n",
    "\n",
    "A = numpy.random.randn(*problem_size).astype(numpy.float32)\n",
    "B = numpy.random.randn(*problem_size).astype(numpy.float32)\n",
    "C = numpy.zeros_like(A)\n",
    "\n",
    "args = [C, A, B]\n",
    "tune_params = OrderedDict()\n",
    "tune_params[\"block_size_x\"] = [16*2**i for i in range(3)]\n",
    "tune_params[\"block_size_y\"] = [2**i for i in range(6)]\n",
    "\n",
    "answer = [numpy.dot(A,B), None, None]\n",
    "\n",
    "results = kernel_tuner.tune_kernel(\"matmul_kernel\", \"matmul_naive.cu\",\n",
    "                                   problem_size, args, tune_params, answer=answer, atol=1e-3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There aren't many parameters to tune yet, and more importantly, tuning will not be very effective because this kernel will be limited by bandwidth rather than compute. There is however, a lot of opportunity for data reuse, which is realized by making the threads in a thread block collaborate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The utilisation of the GPU is still very low:\n",
    "\n",
    "![](Matmul-naive-utilisation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increase data reuse\n",
    "\n",
    "This can be solved by using a technique called loop-blocking or loop-tiling. We define two square data structures in shared memory, which will be used for storing square parts of matrix A and B. The threads in a thread block will collaboratively fill these two variables, and then proceed to perform all the computations that need this data, before moving to the next blocked iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load matmul_data_reuse.cu\n",
    "__global__ void matmul_kernel(float *C, float *A, float *B) {\n",
    "\n",
    "    __shared__ float sA[block_size][block_size];\n",
    "    __shared__ float sB[block_size][block_size];\n",
    "\n",
    "    int tx = threadIdx.x;\n",
    "    int ty = threadIdx.y;\n",
    "    int x = blockIdx.x * block_size + tx;\n",
    "    int y = blockIdx.y * block_size + ty;\n",
    "\n",
    "    float sum = 0.0;\n",
    "    int k,kb;\n",
    "\n",
    "    for (k=0; k<WIDTH; k+=block_size) {\n",
    "        __synchthreads();\n",
    "        sA[ty][tx] = A[y*WIDTH+k+tx];\n",
    "        sB[ty][tx] = B[(k+ty)*WIDTH+x];\n",
    "        __synchthreads();\n",
    "\n",
    "        for (kb=0; kb<block_size; kb++) {\n",
    "            sum += sA[ty][kb] * sB[kb][tx];\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "    C[y*WIDTH+x] = sum;\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
